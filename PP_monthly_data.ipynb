{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1963-07-31</th>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-08-31</th>\n",
       "      <td>5.07</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-09-30</th>\n",
       "      <td>-1.57</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-10-31</th>\n",
       "      <td>2.53</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>-2.01</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-11-30</th>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mkt-RF   SMB   HML   RMW   CMA    RF\n",
       "date                                            \n",
       "1963-07-31   -0.39 -0.41 -0.97  0.68 -1.18  0.27\n",
       "1963-08-31    5.07 -0.80  1.80  0.36 -0.35  0.25\n",
       "1963-09-30   -1.57 -0.52  0.13 -0.71  0.29  0.27\n",
       "1963-10-31    2.53 -1.39 -0.10  2.80 -2.01  0.29\n",
       "1963-11-30   -0.85 -0.88  1.75 -0.51  2.24  0.27"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "\n",
    "starting_year_to_filter = 1963\n",
    "end_year_to_filter = 2020\n",
    "number_of_lookback_periods = 120\n",
    "data_to_read_address = \"data/25_Portfolios_5x5_size_value_monthly.CSV\"\n",
    "factor_data_address = \"data/F-F_Research_Data_5_Factors_2x3.csv\"\n",
    "number_of_PPs_to_consider = 3\n",
    "number_of_PEPs_to_consider = 3\n",
    "number_of_PAPs_to_consider = 3\n",
    "\n",
    "def rank_and_map(df):\n",
    "    # Make a copy to avoid modifying the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "    # Exclude the 'date' column for ranking\n",
    "    data_columns = df_copy.columns[1:]\n",
    "    \n",
    "    # Apply ranking and scaling row-wise (for each date)\n",
    "    def rank_row(row):\n",
    "        # Get the ranks (min rank is 1)\n",
    "        ranks = row.rank(method='min')\n",
    "        # Normalize the ranks to range between 0 and 1\n",
    "        ranks_normalized = (ranks - 1) / (len(row) - 1)\n",
    "        # Map to range [-0.5, 0.5]\n",
    "        return ranks_normalized - 0.5\n",
    "    \n",
    "    # Apply rank_row function to each row, excluding the 'date' column\n",
    "    df_copy[data_columns] = df_copy[data_columns].apply(rank_row, axis=1)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def cross_sectional_demean(df):\n",
    "    # Make a copy to avoid modifying the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "    # Exclude the 'date' column\n",
    "    data_columns = df_copy.columns[1:]\n",
    "    \n",
    "    # Apply demeaning row-wise (for each date)\n",
    "    def demean_row(row):\n",
    "        row_mean = row.mean()  # Compute the mean of the row\n",
    "        return row - row_mean  # Subtract the mean from each element in the row\n",
    "    \n",
    "    # Apply demean_row function to each row, excluding the 'date' column\n",
    "    df_copy[data_columns] = df_copy[data_columns].apply(demean_row, axis=1)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def compute_rs_product(df1, df2):\n",
    "    # Ensure the date columns match\n",
    "    if not df1['date'].equals(df2['date']):\n",
    "        raise ValueError(\"Date columns of both dataframes must match.\")\n",
    "    \n",
    "  # Convert to numeric, set invalid values as NaN\n",
    "    df1 = df1.astype({col: 'float64' for col in df1.columns if col != 'date'})\n",
    "    df2 = df2.astype({col: 'float64' for col in df2.columns if col != 'date'})\n",
    "    result = {}\n",
    "    \n",
    "    # Iterate over each row (each date)\n",
    "    for index, date in enumerate(df1['date']):\n",
    "        # Get the R vector (from df1) and S' vector (from df2) for the current date\n",
    "        R = df1.iloc[index, 1:].values.reshape(-1, 1)  # n x 1 vector\n",
    "        S_transpose = df2.iloc[index, 1:].values.reshape(1, -1)  # 1 x n vector\n",
    "        # Compute the outer product (RS')\n",
    "        matrix_rs = np.dot(R, S_transpose)  # n x n matrix\n",
    "        # Store the result in a dictionary, with date as the key\n",
    "        result[date] = matrix_rs\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_prediction_matrix(input_date, result_matrices, n_periods):\n",
    "    # Sort the dates in result_matrices to ensure they're in order\n",
    "    sorted_dates = sorted(result_matrices.keys())\n",
    "    # Find the index of the input date in the sorted list of dates\n",
    "    if input_date not in sorted_dates:\n",
    "        raise ValueError(\"The input date is not found in the result_matrices.\")\n",
    "    \n",
    "    input_date_index = sorted_dates.index(input_date)\n",
    "    # Select the last n_periods (excluding the input date)\n",
    "    start_index = max(0, input_date_index - n_periods)  # Ensure we don't go below index 0\n",
    "    selected_dates = sorted_dates[start_index:input_date_index]\n",
    "    \n",
    "    if len(selected_dates) == 0:\n",
    "        raise ValueError(f\"There are no previous periods to calculate the average for the given number: {n_periods}.\")\n",
    "    \n",
    "    # Initialize a matrix to accumulate the sum\n",
    "    matrix_shape = result_matrices[sorted_dates[0]].shape\n",
    "    sum_matrix = np.zeros(matrix_shape, dtype=float)\n",
    "    # Sum all the selected matrices\n",
    "    for date in selected_dates:\n",
    "        sum_matrix += np.array(result_matrices[date], dtype=float)\n",
    "    \n",
    "    # Calculate the element-wise average\n",
    "    average_matrix = sum_matrix / len(selected_dates)\n",
    "    return average_matrix\n",
    "\n",
    "\n",
    "# i should start from 0. In other words, to get the first PP's expected return you must set i=0.\n",
    "def get_ith_PPs_expected_return(S,i):\n",
    "    return S[i]\n",
    "\n",
    "# i should start from 0. In other words, to get the first PP you must set i=0.\n",
    "def get_ith_position_matrix(U,VT,i):\n",
    "    u_column = U[:, i]\n",
    "    v_column = VT[i, :]\n",
    "    return np.outer(v_column,u_column)\n",
    "\n",
    "def first_n_PPs_expected_return(S,n):\n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        sum += get_ith_PPs_expected_return(S,i)\n",
    "    return sum\n",
    "\n",
    "def first_n_PPs_position_matrix(U,VT,number_of_PPs):\n",
    "    matrix_shape = U.shape\n",
    "    sum_matrix = np.zeros(matrix_shape, dtype=float)\n",
    "    for i in range(number_of_PPs):\n",
    "        sum_matrix += get_ith_position_matrix(U,VT,i)\n",
    "    return sum_matrix/number_of_PPs\n",
    "\n",
    "\n",
    "# i should start from 0. In other words, to get the first PEP you must set i=0.\n",
    "def get_ith_PEPs_expected_return(eigenvalues,i):\n",
    "    return eigenvalues[i]\n",
    "\n",
    "def get_ith_symmetric_position_matrix(eigenvectors,i):\n",
    "    w = eigenvectors[:, i]\n",
    "    return np.outer(w,w)\n",
    "\n",
    "def first_n_PEPs_expected_return(eigenvalues,n):\n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        sum += abs(get_ith_PEPs_expected_return(eigenvalues,i))\n",
    "    return sum\n",
    "\n",
    "def first_n_PEPs_position_matrix(eigenvectors,number_of_PEPs):\n",
    "    matrix_shape = eigenvectors.shape\n",
    "    sum_matrix = np.zeros(matrix_shape, dtype=float)\n",
    "    for i in range(number_of_PEPs):\n",
    "        sum_matrix += get_ith_symmetric_position_matrix(eigenvectors,i)\n",
    "    return sum_matrix/number_of_PEPs\n",
    "\n",
    "# i should start from 0. In other words, to get the first PEP you must set i=0.\n",
    "def get_ith_PAPs_expected_return(filtered_eigenvalues_ta,i):\n",
    "    return 2 * filtered_eigenvalues_ta[i]\n",
    "\n",
    "def get_ith_asymmetric_position_matrix(sorted_eigenvectors_ta_real_part,sorted_eigenvectors_ta_imaginary_part,i):\n",
    "    return np.outer(sorted_eigenvectors_ta_real_part[:,i],sorted_eigenvectors_ta_imaginary_part[:,i]) - np.outer(sorted_eigenvectors_ta_imaginary_part[:,i],sorted_eigenvectors_ta_real_part[:,i])\n",
    "    \n",
    "def first_n_PAPs_expected_return(filtered_eigenvalues_ta,n):\n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        sum += get_ith_PAPs_expected_return(filtered_eigenvalues_ta,i)\n",
    "    return sum\n",
    "\n",
    "def first_n_PAPs_position_matrix(sorted_eigenvectors_ta_real_part,sorted_eigenvectors_ta_imaginary_part,number_of_PAPs):\n",
    "    number_of_rows = sorted_eigenvectors_ta_real_part.shape[0]\n",
    "    sum_matrix = np.zeros((number_of_rows,number_of_rows), dtype=float)\n",
    "    for i in range(number_of_PAPs):\n",
    "        sum_matrix += get_ith_asymmetric_position_matrix(sorted_eigenvectors_ta_real_part,sorted_eigenvectors_ta_imaginary_part,i)\n",
    "    return sum_matrix/number_of_PAPs\n",
    "\n",
    "def calculate_sharpe_ratio(returns):\n",
    "    # Compute excess returns\n",
    "    \n",
    "    # Compute average excess return\n",
    "    average_return = returns.mean()\n",
    "    \n",
    "    # Compute standard deviation of returns\n",
    "    std_dev_returns = returns.std()\n",
    "    \n",
    "    # Compute Sharpe Ratio\n",
    "    sharpe_ratio = average_return / std_dev_returns\n",
    "    \n",
    "    return sharpe_ratio\n",
    "\n",
    "def filter_dataframes_by_common_dates(df1, df2):\n",
    "    # Find common dates (intersection of index values)\n",
    "    common_dates = df1.index.intersection(df2.index)\n",
    "    \n",
    "    # Filter both dataframes to keep only the rows with the common dates\n",
    "    df1_filtered = df1.loc[common_dates]\n",
    "    df2_filtered = df2.loc[common_dates]\n",
    "    \n",
    "    return df1_filtered, df2_filtered\n",
    "\n",
    "\n",
    "def regression_results(X, Y):\n",
    "    # Get the standard deviation of X[1] (which is the first non-constant column of X)\n",
    "    std_X1 = X.iloc[:, 1].std()  # Assuming X[1] is the first non-constant column\n",
    "\n",
    "    # Scale Y to have the same standard deviation as X[1]\n",
    "    std_Y = Y.std()\n",
    "    Y_scaled = Y * (std_X1 / std_Y)  # Scale Y by the ratio of std_X1 to std_Y\n",
    "\n",
    "    # Add a constant (intercept) to the independent variables\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Fit the model\n",
    "    model = sm.OLS(Y_scaled, X).fit()\n",
    "\n",
    "    # Get the coefficients (including the intercept)\n",
    "    coefficients = model.params.values\n",
    "\n",
    "    # Get the t-statistics\n",
    "    t_stats = model.tvalues.values\n",
    "\n",
    "    # Calculate the standard deviation of residuals\n",
    "    residuals = model.resid\n",
    "    std_residuals = residuals.std(ddof=1)  # Sample standard deviation (ddof=1)\n",
    "\n",
    "    # Calculate intercept divided by standard deviation of residuals\n",
    "    intercept_over_std_residuals = (coefficients[0] / std_residuals) * math.sqrt(12) #sqrt(12) is to make the IR annualized. again, to make comparison with Kelly's paper easier.\n",
    "\n",
    "    # Get the R-squared value\n",
    "    r_squared = model.rsquared\n",
    "\n",
    "    coefficients[0] = coefficients[0] * 12 # This is to make the results comparable to Kelly(2022). They report annualized alphas in their tables.\n",
    "\n",
    "    # Return the list as required\n",
    "    return [coefficients, t_stats, intercept_over_std_residuals, r_squared]\n",
    "\n",
    "\n",
    "factor_data_monthly = pd.read_csv(factor_data_address)\n",
    "factor_data_monthly['date'] = pd.to_datetime(factor_data_monthly['date'], format='%Y%m') + pd.offsets.MonthEnd(1)\n",
    "factor_data_monthly = factor_data_monthly.set_index(\"date\")\n",
    "factor_data_monthly.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_PP(data_to_read_address, factor_data_monthly):\n",
    "    \n",
    "    df_25_ff_size_value_sorted_monthly = pd.read_csv(data_to_read_address)\n",
    "    df_25_ff_size_value_sorted_monthly['date'] = pd.to_datetime(df_25_ff_size_value_sorted_monthly['date'], format='%Y%m') + pd.offsets.MonthEnd(1)\n",
    "    \n",
    "    signal_df = pd.DataFrame()\n",
    "    signal_df[\"date\"] = df_25_ff_size_value_sorted_monthly[\"date\"]\n",
    "    # Note that I shift signals one period forward to make computations easier. \n",
    "    signal_df= signal_df.join(df_25_ff_size_value_sorted_monthly.iloc[:, 1:].shift(1))\n",
    "    # I can think of this matrix as $S_{t-1}$.\n",
    "    normalized_signal_df = rank_and_map(signal_df)\n",
    "    normalized_signal_df = normalized_signal_df[(normalized_signal_df['date'].dt.year > starting_year_to_filter) & (normalized_signal_df['date'].dt.year < end_year_to_filter)].reset_index(drop=True)\n",
    "    # This matrix can be denoted as $R_{t-1}$\n",
    "    demeaned_return_df = cross_sectional_demean(df_25_ff_size_value_sorted_monthly)\n",
    "    demeaned_return_df = demeaned_return_df[(demeaned_return_df['date'].dt.year > starting_year_to_filter) & (demeaned_return_df['date'].dt.year < end_year_to_filter)].reset_index(drop=True)\n",
    "    # This gives: $R_{t}S'_{t}$\n",
    "    rs_matrix = compute_rs_product(demeaned_return_df, normalized_signal_df)\n",
    "    \n",
    "    \"\"\"\n",
    "    Prediction matrix for date T+1, used returns data up to month T and signals data up to month T-1.\n",
    "    In the function get_prediction_matrix, I start the calculations from the previous month. \n",
    "    Note that although the input date is the current data, but the in the function that month is excluded.\n",
    "    Note that in calculating realized returns, I am using the current month(the month of rearlized returns) as index. \n",
    "    But remember that the matrix was $S_{t-1}$. So, the index actually retreives the value of the previous month. \n",
    "    I formed the matrix this way in order to make the calculations easier.\n",
    "    \"\"\"\n",
    "\n",
    "    realized_returns_df = pd.DataFrame(columns=[\n",
    "        \"date\",\n",
    "        \"return_of_simple_factor\", \n",
    "        \"realized_return_of_first_three_PP\", \n",
    "        \"expected_return_of_first_three_PP\",\n",
    "        \"realized_return_of_first_three_PEP\",\n",
    "        \"expected_return_of_first_three_PEP\",\n",
    "        \"realized_return_of_first_three_PAP\",\n",
    "        \"expected_return_of_first_three_PAP\"\n",
    "    ])\n",
    "\n",
    "    # I leave out the first 120 (number of lookback periods) observations to compute the prediction matrix.\n",
    "    for date_index in demeaned_return_df.iloc[number_of_lookback_periods:]['date']:\n",
    "        date_to_consider = pd.Timestamp(date_index)\n",
    "        \n",
    "        #for PP's\n",
    "        prediction_matrix = get_prediction_matrix(date_to_consider, rs_matrix, number_of_lookback_periods)\n",
    "        U, S, VT = np.linalg.svd(prediction_matrix)\n",
    "\n",
    "        #for PEP's\n",
    "        Symmetric_prediction_matrix = (prediction_matrix + prediction_matrix.T)/2\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(Symmetric_prediction_matrix)\n",
    "        idx = eigenvalues.argsort()[::-1]  # Sort in descending order\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "        # for PAP'S\n",
    "        assymetric_prediction_matrix = 0.5 * (prediction_matrix - prediction_matrix.T)\n",
    "        transposed_assymetric_prediction_matrix = assymetric_prediction_matrix.T\n",
    "        eigenvalues_ta, eigenvectors_ta = np.linalg.eig(transposed_assymetric_prediction_matrix)\n",
    "        sorted_indices_ta = np.argsort(-eigenvalues_ta.imag)\n",
    "        sorted_eigenvalues_ta = eigenvalues_ta[sorted_indices_ta].imag\n",
    "        sorted_eigenvectors_ta = eigenvectors_ta[:, sorted_indices_ta] * math.sqrt(2)  #sqrt(2) is to make the size of the vectors equal to 1.\n",
    "        positive_indices = np.where(sorted_eigenvalues_ta > 0)\n",
    "        filtered_eigenvalues_ta = sorted_eigenvalues_ta[positive_indices]\n",
    "        filtered_eigenvectors_ta = sorted_eigenvectors_ta[:, positive_indices].squeeze()\n",
    "        sorted_eigenvectors_ta_imaginary_part = filtered_eigenvectors_ta.imag\n",
    "        sorted_eigenvectors_ta_real_part = filtered_eigenvectors_ta.real\n",
    "\n",
    "        #to calculate realized returns\n",
    "        signal_vector = normalized_signal_df[normalized_signal_df.date == date_to_consider].values[0, 1:].reshape(1, -1)  # 1*n matrix\n",
    "        return_vector = df_25_ff_size_value_sorted_monthly[df_25_ff_size_value_sorted_monthly.date == date_to_consider].values[0, 1:].reshape(-1, 1)  # n*1  # there is not much difference between using demeaned returns or not_demeaned ones. I can replace df_25_ff_size_value_sorted_monthly with demeaned_return_df.\n",
    "        \n",
    "\n",
    "        # Compute realized returns\n",
    "        return_of_simple_factor = (signal_vector @ return_vector)[0][0]\n",
    "        realized_return_of_first_three_PP = (signal_vector @ first_n_PPs_position_matrix(U, VT, number_of_PPs_to_consider) @ return_vector)[0][0]\n",
    "        expected_return_of_first_three_PP = first_n_PPs_expected_return(S, number_of_PPs_to_consider)\n",
    "        realized_return_of_first_three_PEP = (signal_vector @ first_n_PEPs_position_matrix(eigenvectors,number_of_PEPs_to_consider) @ return_vector)[0][0]\n",
    "        expected_return_of_first_three_PEP = first_n_PEPs_expected_return(eigenvalues, number_of_PEPs_to_consider)\n",
    "        realized_return_of_first_three_PAP = (signal_vector @ first_n_PAPs_position_matrix(sorted_eigenvectors_ta_real_part,sorted_eigenvectors_ta_imaginary_part,number_of_PAPs_to_consider) @ return_vector)[0][0]\n",
    "        expected_return_of_first_three_PAP = first_n_PAPs_expected_return(filtered_eigenvalues_ta, number_of_PAPs_to_consider)\n",
    "        \n",
    "\n",
    "        # Prepare a list for the current row values\n",
    "        row_values = [\n",
    "            date_index,\n",
    "            return_of_simple_factor,  \n",
    "            realized_return_of_first_three_PP, \n",
    "            expected_return_of_first_three_PP,\n",
    "            realized_return_of_first_three_PEP,\n",
    "            expected_return_of_first_three_PEP,\n",
    "            realized_return_of_first_three_PAP,\n",
    "            expected_return_of_first_three_PAP\n",
    "        ]\n",
    "\n",
    "        # Iterate over all Principal Portfolios (up to len(S)) and calculate realized/expected returns for each\n",
    "        for i in range(len(S)):\n",
    "\n",
    "            # for PP's\n",
    "            realized_return_ith_PP = (signal_vector @ get_ith_position_matrix(U, VT, i) @ return_vector)[0][0]\n",
    "            expected_return_ith_PP = get_ith_PPs_expected_return(S, i)\n",
    "            # Add the values for realized and expected returns of the ith PP to the row\n",
    "            row_values.append(realized_return_ith_PP)\n",
    "            row_values.append(expected_return_ith_PP)\n",
    "\n",
    "            # for PEP's\n",
    "            realized_return_ith_PEP = (signal_vector @ get_ith_symmetric_position_matrix(eigenvectors, i) @ return_vector)[0][0]\n",
    "            expected_return_ith_PEP = get_ith_PEPs_expected_return(eigenvalues, i)\n",
    "            # Add the values for realized and expected returns of the ith PEP to the row\n",
    "            row_values.append(realized_return_ith_PEP)\n",
    "            row_values.append(expected_return_ith_PEP)\n",
    "\n",
    "\n",
    "            # Dynamically add columns if they don't exist. for PP's.\n",
    "            realized_col_name_pp = f\"realized_return_of_{i+1}_PP\"\n",
    "            expected_col_name_pp = f\"expected_return_of_{i+1}_PP\"\n",
    "\n",
    "            # Dynamically add columns if they don't exist. for PEP's.\n",
    "            realized_col_name_pep = f\"realized_return_of_{i+1}_PEP\"\n",
    "            expected_col_name_pep = f\"expected_return_of_{i+1}_PEP\"\n",
    "            \n",
    "            # for PP's\n",
    "            if realized_col_name_pp not in realized_returns_df.columns:\n",
    "                realized_returns_df[realized_col_name_pp] = None\n",
    "            if expected_col_name_pp not in realized_returns_df.columns:\n",
    "                realized_returns_df[expected_col_name_pp] = None\n",
    "\n",
    "            #for PEP'S\n",
    "            if realized_col_name_pep not in realized_returns_df.columns:\n",
    "                realized_returns_df[realized_col_name_pep] = None\n",
    "            if expected_col_name_pep not in realized_returns_df.columns:\n",
    "                realized_returns_df[expected_col_name_pep] = None\n",
    "                \n",
    "        # The number of PAP's is different, so another loop is needed.\n",
    "        for i in range(sorted_eigenvectors_ta_imaginary_part.shape[1]):\n",
    "            # for PAP's\n",
    "            realized_return_ith_PAP = (signal_vector @ get_ith_asymmetric_position_matrix(sorted_eigenvectors_ta_real_part,sorted_eigenvectors_ta_imaginary_part,i) @ return_vector)[0][0]\n",
    "            expected_return_ith_PAP = get_ith_PAPs_expected_return(filtered_eigenvalues_ta,i)\n",
    "            # Add the values for realized and expected returns of the ith PEP to the row\n",
    "            row_values.append(realized_return_ith_PAP)\n",
    "            row_values.append(expected_return_ith_PAP)\n",
    "\n",
    "            # Dynamically add columns if they don't exist. for PEP's.\n",
    "            realized_col_name_pap = f\"realized_return_of_{i+1}_PAP\"\n",
    "            expected_col_name_pap = f\"expected_return_of_{i+1}_PAP\"\n",
    "\n",
    "            #for PAP'S\n",
    "            if realized_col_name_pap not in realized_returns_df.columns:\n",
    "                realized_returns_df[realized_col_name_pap] = None\n",
    "            if expected_col_name_pap not in realized_returns_df.columns:\n",
    "                realized_returns_df[expected_col_name_pap] = None\n",
    "\n",
    "        # Append the row to the dataframe\n",
    "        realized_returns_df.loc[len(realized_returns_df)] = row_values\n",
    "\n",
    "    realized_returns_df = realized_returns_df.set_index(\"date\")\n",
    "\n",
    "    pap_std = realized_returns_df['realized_return_of_first_three_PAP'].std()\n",
    "    pep_std = realized_returns_df['realized_return_of_first_three_PEP'].std()\n",
    "    realized_returns_df['adjusted_PAP'] = realized_returns_df['realized_return_of_first_three_PAP'] * (pep_std / pap_std)\n",
    "    # Take the average of the adjusted \"PAP\" and \"PEP\"\n",
    "    realized_returns_df['PEP and PAP 1-3'] = (realized_returns_df['adjusted_PAP'] + realized_returns_df['realized_return_of_first_three_PEP']) / 2\n",
    "    # drop the adjusted column.\n",
    "    realized_returns_df.drop(columns='adjusted_PAP', inplace=True)\n",
    "\n",
    "    sharpe_df = realized_returns_df.drop(realized_returns_df.filter(like=\"expected\").columns, axis=1).apply(lambda col: calculate_sharpe_ratio(col)) * math.sqrt(12)\n",
    "\n",
    "    pp_columns = realized_returns_df.filter(like=\"PP\")\n",
    "    pp_realized_mean_df = pp_columns.filter(like=\"realized\").mean(axis=0)\n",
    "    pp_expected_mean_df = pp_columns.filter(like=\"expected\").mean(axis=0)\n",
    "\n",
    "    pep_columns = realized_returns_df.filter(like=\"PEP\")\n",
    "    pep_realized_mean_df = pep_columns.filter(like=\"realized\").mean(axis=0)\n",
    "    pep_expected_mean_df = pep_columns.filter(like=\"expected\").mean(axis=0)\n",
    "\n",
    "    pap_columns = realized_returns_df.filter(like=\"PAP\")\n",
    "    pap_realized_mean_df = pap_columns.filter(like=\"realized\").mean(axis=0)\n",
    "    pap_expected_mean_df = pap_columns.filter(like=\"expected\").mean(axis=0)\n",
    "\n",
    "    output_dict = {\n",
    "    'realized_returns_df': realized_returns_df,\n",
    "    'sharpe_df': sharpe_df,\n",
    "    'pp_realized_mean_df': pp_realized_mean_df,\n",
    "    'pp_expected_mean_df': pp_expected_mean_df,\n",
    "    'pep_realized_mean_df': pep_realized_mean_df,\n",
    "    'pep_expected_mean_df': pep_expected_mean_df,\n",
    "    'pap_realized_mean_df': pap_realized_mean_df,\n",
    "    'pap_expected_mean_df': pap_expected_mean_df\n",
    "    }\n",
    "\n",
    "    \n",
    "    realized_returns_df, factor_data_monthly = filter_dataframes_by_common_dates(realized_returns_df,factor_data_monthly)\n",
    "    X = factor_data_monthly[['Mkt-RF', 'SMB','HML','RMW','CMA']]\n",
    "    Y = realized_returns_df['return_of_simple_factor']\n",
    "    output_dict[\"regression_result_return_of_simple_factor\"] = regression_results(X,Y)\n",
    "\n",
    "    # Following Kelly's paper. For regressions that have PP's as Y, simple factor must be addes as X.\n",
    "    X = pd.concat([X, realized_returns_df['return_of_simple_factor']], axis=1)\n",
    "    # List of column names in realized_returns_df for which I want to perform the regression\n",
    "    columns_to_iterate = ['realized_return_of_first_three_PP',\n",
    "                      'realized_return_of_first_three_PEP',\n",
    "                      'realized_return_of_first_three_PAP',\n",
    "                       'PEP and PAP 1-3'] \n",
    "\n",
    "    # Iterate over each column\n",
    "    for col in columns_to_iterate:\n",
    "        # Set Y to the column from realized_returns_df\n",
    "        Y = realized_returns_df[col]\n",
    "        # Store the results with a variable name based on the column name\n",
    "        result_name = f'regression_result_{col}'\n",
    "        output_dict[result_name] = regression_results(X,Y)\n",
    "    return output_dict  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SMALL LoBM</th>\n",
       "      <th>ME1 BM2</th>\n",
       "      <th>ME1 BM3</th>\n",
       "      <th>ME1 BM4</th>\n",
       "      <th>SMALL HiBM</th>\n",
       "      <th>ME2 BM1</th>\n",
       "      <th>ME2 BM2</th>\n",
       "      <th>ME2 BM3</th>\n",
       "      <th>ME2 BM4</th>\n",
       "      <th>...</th>\n",
       "      <th>ME4 BM1</th>\n",
       "      <th>ME4 BM2</th>\n",
       "      <th>ME4 BM3</th>\n",
       "      <th>ME4 BM4</th>\n",
       "      <th>ME4 BM5</th>\n",
       "      <th>BIG LoBM</th>\n",
       "      <th>ME5 BM2</th>\n",
       "      <th>ME5 BM3</th>\n",
       "      <th>ME5 BM4</th>\n",
       "      <th>BIG HiBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1926-07-31</td>\n",
       "      <td>5.8248</td>\n",
       "      <td>-1.7006</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>-1.4580</td>\n",
       "      <td>2.0534</td>\n",
       "      <td>1.2077</td>\n",
       "      <td>2.4192</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>-2.6049</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5893</td>\n",
       "      <td>1.5278</td>\n",
       "      <td>1.2978</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>2.4678</td>\n",
       "      <td>3.4539</td>\n",
       "      <td>6.0902</td>\n",
       "      <td>2.0266</td>\n",
       "      <td>3.1111</td>\n",
       "      <td>0.5623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1926-08-31</td>\n",
       "      <td>-2.0206</td>\n",
       "      <td>-8.0282</td>\n",
       "      <td>1.3796</td>\n",
       "      <td>1.4606</td>\n",
       "      <td>8.3968</td>\n",
       "      <td>2.3618</td>\n",
       "      <td>-1.1849</td>\n",
       "      <td>4.0084</td>\n",
       "      <td>0.5038</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3336</td>\n",
       "      <td>3.8730</td>\n",
       "      <td>2.0021</td>\n",
       "      <td>2.1706</td>\n",
       "      <td>5.3422</td>\n",
       "      <td>1.0124</td>\n",
       "      <td>4.1903</td>\n",
       "      <td>2.0131</td>\n",
       "      <td>5.4849</td>\n",
       "      <td>7.7576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1926-09-30</td>\n",
       "      <td>-4.8291</td>\n",
       "      <td>-2.6154</td>\n",
       "      <td>-4.3417</td>\n",
       "      <td>-3.2729</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>-2.6540</td>\n",
       "      <td>-1.2618</td>\n",
       "      <td>1.0829</td>\n",
       "      <td>-3.5480</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0923</td>\n",
       "      <td>-0.5250</td>\n",
       "      <td>-1.7636</td>\n",
       "      <td>1.4646</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>-1.2906</td>\n",
       "      <td>3.6538</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>-0.7487</td>\n",
       "      <td>-2.4284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1926-10-31</td>\n",
       "      <td>-9.3729</td>\n",
       "      <td>-3.5519</td>\n",
       "      <td>-3.4948</td>\n",
       "      <td>3.4413</td>\n",
       "      <td>-2.5476</td>\n",
       "      <td>-2.8069</td>\n",
       "      <td>-3.2663</td>\n",
       "      <td>-5.0745</td>\n",
       "      <td>-8.0191</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.3361</td>\n",
       "      <td>-2.6559</td>\n",
       "      <td>-2.1070</td>\n",
       "      <td>-3.1051</td>\n",
       "      <td>-5.3525</td>\n",
       "      <td>-2.7413</td>\n",
       "      <td>-3.0071</td>\n",
       "      <td>-2.2437</td>\n",
       "      <td>-4.6719</td>\n",
       "      <td>-5.8129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1926-11-30</td>\n",
       "      <td>5.5888</td>\n",
       "      <td>4.1877</td>\n",
       "      <td>2.4623</td>\n",
       "      <td>-4.4494</td>\n",
       "      <td>0.5362</td>\n",
       "      <td>3.1033</td>\n",
       "      <td>-2.3690</td>\n",
       "      <td>3.0078</td>\n",
       "      <td>5.1546</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4448</td>\n",
       "      <td>2.3887</td>\n",
       "      <td>3.7335</td>\n",
       "      <td>4.9320</td>\n",
       "      <td>1.8213</td>\n",
       "      <td>4.2946</td>\n",
       "      <td>2.5326</td>\n",
       "      <td>1.5204</td>\n",
       "      <td>3.6619</td>\n",
       "      <td>2.5636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  SMALL LoBM  ME1 BM2  ME1 BM3  ME1 BM4  SMALL HiBM  ME2 BM1   \n",
       "0 1926-07-31      5.8248  -1.7006   0.4875  -1.4580      2.0534   1.2077  \\\n",
       "1 1926-08-31     -2.0206  -8.0282   1.3796   1.4606      8.3968   2.3618   \n",
       "2 1926-09-30     -4.8291  -2.6154  -4.3417  -3.2729      0.8649  -2.6540   \n",
       "3 1926-10-31     -9.3729  -3.5519  -3.4948   3.4413     -2.5476  -2.8069   \n",
       "4 1926-11-30      5.5888   4.1877   2.4623  -4.4494      0.5362   3.1033   \n",
       "\n",
       "   ME2 BM2  ME2 BM3  ME2 BM4  ...  ME4 BM1  ME4 BM2  ME4 BM3  ME4 BM4   \n",
       "0   2.4192   0.4926  -2.6049  ...   1.5893   1.5278   1.2978   0.2727  \\\n",
       "1  -1.1849   4.0084   0.5038  ...   1.3336   3.8730   2.0021   2.1706   \n",
       "2  -1.2618   1.0829  -3.5480  ...   1.0923  -0.5250  -1.7636   1.4646   \n",
       "3  -3.2663  -5.0745  -8.0191  ...  -3.3361  -2.6559  -2.1070  -3.1051   \n",
       "4  -2.3690   3.0078   5.1546  ...   3.4448   2.3887   3.7335   4.9320   \n",
       "\n",
       "   ME4 BM5  BIG LoBM  ME5 BM2  ME5 BM3  ME5 BM4  BIG HiBM  \n",
       "0   2.4678    3.4539   6.0902   2.0266   3.1111    0.5623  \n",
       "1   5.3422    1.0124   4.1903   2.0131   5.4849    7.7576  \n",
       "2   0.8730   -1.2906   3.6538   0.0950  -0.7487   -2.4284  \n",
       "3  -5.3525   -2.7413  -3.0071  -2.2437  -4.6719   -5.8129  \n",
       "4   1.8213    4.2946   2.5326   1.5204   3.6619    2.5636  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_25_ff_size_value_sorted_monthly = pd.read_csv(data_to_read_address)\n",
    "df_25_ff_size_value_sorted_monthly['date'] = pd.to_datetime(df_25_ff_size_value_sorted_monthly['date'], format='%Y%m') + pd.offsets.MonthEnd(1)\n",
    "df_25_ff_size_value_sorted_monthly.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I shift signals one period forward to make computations easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SMALL LoBM</th>\n",
       "      <th>ME1 BM2</th>\n",
       "      <th>ME1 BM3</th>\n",
       "      <th>ME1 BM4</th>\n",
       "      <th>SMALL HiBM</th>\n",
       "      <th>ME2 BM1</th>\n",
       "      <th>ME2 BM2</th>\n",
       "      <th>ME2 BM3</th>\n",
       "      <th>ME2 BM4</th>\n",
       "      <th>...</th>\n",
       "      <th>ME4 BM1</th>\n",
       "      <th>ME4 BM2</th>\n",
       "      <th>ME4 BM3</th>\n",
       "      <th>ME4 BM4</th>\n",
       "      <th>ME4 BM5</th>\n",
       "      <th>BIG LoBM</th>\n",
       "      <th>ME5 BM2</th>\n",
       "      <th>ME5 BM3</th>\n",
       "      <th>ME5 BM4</th>\n",
       "      <th>BIG HiBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1926-07-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1926-08-31</td>\n",
       "      <td>5.8248</td>\n",
       "      <td>-1.7006</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>-1.4580</td>\n",
       "      <td>2.0534</td>\n",
       "      <td>1.2077</td>\n",
       "      <td>2.4192</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>-2.6049</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5893</td>\n",
       "      <td>1.5278</td>\n",
       "      <td>1.2978</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>2.4678</td>\n",
       "      <td>3.4539</td>\n",
       "      <td>6.0902</td>\n",
       "      <td>2.0266</td>\n",
       "      <td>3.1111</td>\n",
       "      <td>0.5623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1926-09-30</td>\n",
       "      <td>-2.0206</td>\n",
       "      <td>-8.0282</td>\n",
       "      <td>1.3796</td>\n",
       "      <td>1.4606</td>\n",
       "      <td>8.3968</td>\n",
       "      <td>2.3618</td>\n",
       "      <td>-1.1849</td>\n",
       "      <td>4.0084</td>\n",
       "      <td>0.5038</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3336</td>\n",
       "      <td>3.8730</td>\n",
       "      <td>2.0021</td>\n",
       "      <td>2.1706</td>\n",
       "      <td>5.3422</td>\n",
       "      <td>1.0124</td>\n",
       "      <td>4.1903</td>\n",
       "      <td>2.0131</td>\n",
       "      <td>5.4849</td>\n",
       "      <td>7.7576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1926-10-31</td>\n",
       "      <td>-4.8291</td>\n",
       "      <td>-2.6154</td>\n",
       "      <td>-4.3417</td>\n",
       "      <td>-3.2729</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>-2.6540</td>\n",
       "      <td>-1.2618</td>\n",
       "      <td>1.0829</td>\n",
       "      <td>-3.5480</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0923</td>\n",
       "      <td>-0.5250</td>\n",
       "      <td>-1.7636</td>\n",
       "      <td>1.4646</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>-1.2906</td>\n",
       "      <td>3.6538</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>-0.7487</td>\n",
       "      <td>-2.4284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1926-11-30</td>\n",
       "      <td>-9.3729</td>\n",
       "      <td>-3.5519</td>\n",
       "      <td>-3.4948</td>\n",
       "      <td>3.4413</td>\n",
       "      <td>-2.5476</td>\n",
       "      <td>-2.8069</td>\n",
       "      <td>-3.2663</td>\n",
       "      <td>-5.0745</td>\n",
       "      <td>-8.0191</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.3361</td>\n",
       "      <td>-2.6559</td>\n",
       "      <td>-2.1070</td>\n",
       "      <td>-3.1051</td>\n",
       "      <td>-5.3525</td>\n",
       "      <td>-2.7413</td>\n",
       "      <td>-3.0071</td>\n",
       "      <td>-2.2437</td>\n",
       "      <td>-4.6719</td>\n",
       "      <td>-5.8129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  SMALL LoBM  ME1 BM2  ME1 BM3  ME1 BM4  SMALL HiBM  ME2 BM1   \n",
       "0 1926-07-31         NaN      NaN      NaN      NaN         NaN      NaN  \\\n",
       "1 1926-08-31      5.8248  -1.7006   0.4875  -1.4580      2.0534   1.2077   \n",
       "2 1926-09-30     -2.0206  -8.0282   1.3796   1.4606      8.3968   2.3618   \n",
       "3 1926-10-31     -4.8291  -2.6154  -4.3417  -3.2729      0.8649  -2.6540   \n",
       "4 1926-11-30     -9.3729  -3.5519  -3.4948   3.4413     -2.5476  -2.8069   \n",
       "\n",
       "   ME2 BM2  ME2 BM3  ME2 BM4  ...  ME4 BM1  ME4 BM2  ME4 BM3  ME4 BM4   \n",
       "0      NaN      NaN      NaN  ...      NaN      NaN      NaN      NaN  \\\n",
       "1   2.4192   0.4926  -2.6049  ...   1.5893   1.5278   1.2978   0.2727   \n",
       "2  -1.1849   4.0084   0.5038  ...   1.3336   3.8730   2.0021   2.1706   \n",
       "3  -1.2618   1.0829  -3.5480  ...   1.0923  -0.5250  -1.7636   1.4646   \n",
       "4  -3.2663  -5.0745  -8.0191  ...  -3.3361  -2.6559  -2.1070  -3.1051   \n",
       "\n",
       "   ME4 BM5  BIG LoBM  ME5 BM2  ME5 BM3  ME5 BM4  BIG HiBM  \n",
       "0      NaN       NaN      NaN      NaN      NaN       NaN  \n",
       "1   2.4678    3.4539   6.0902   2.0266   3.1111    0.5623  \n",
       "2   5.3422    1.0124   4.1903   2.0131   5.4849    7.7576  \n",
       "3   0.8730   -1.2906   3.6538   0.0950  -0.7487   -2.4284  \n",
       "4  -5.3525   -2.7413  -3.0071  -2.2437  -4.6719   -5.8129  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_df = pd.DataFrame()\n",
    "signal_df[\"date\"] = df_25_ff_size_value_sorted_monthly[\"date\"]\n",
    "signal_df= signal_df.join(df_25_ff_size_value_sorted_monthly.iloc[:, 1:].shift(1))\n",
    "signal_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can think of this matrix as $S_{t-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SMALL LoBM</th>\n",
       "      <th>ME1 BM2</th>\n",
       "      <th>ME1 BM3</th>\n",
       "      <th>ME1 BM4</th>\n",
       "      <th>SMALL HiBM</th>\n",
       "      <th>ME2 BM1</th>\n",
       "      <th>ME2 BM2</th>\n",
       "      <th>ME2 BM3</th>\n",
       "      <th>ME2 BM4</th>\n",
       "      <th>...</th>\n",
       "      <th>ME4 BM1</th>\n",
       "      <th>ME4 BM2</th>\n",
       "      <th>ME4 BM3</th>\n",
       "      <th>ME4 BM4</th>\n",
       "      <th>ME4 BM5</th>\n",
       "      <th>BIG LoBM</th>\n",
       "      <th>ME5 BM2</th>\n",
       "      <th>ME5 BM3</th>\n",
       "      <th>ME5 BM4</th>\n",
       "      <th>BIG HiBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964-01-31</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.458333</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.291667</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1964-02-29</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.458333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.291667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1964-03-31</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.458333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>-0.291667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1964-04-30</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.291667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1964-05-31</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>-0.291667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  SMALL LoBM   ME1 BM2   ME1 BM3   ME1 BM4  SMALL HiBM   ME2 BM1   \n",
       "0 1964-01-31   -0.500000 -0.375000 -0.333333 -0.458333   -0.416667 -0.291667  \\\n",
       "1 1964-02-29    0.333333 -0.041667  0.416667  0.375000    0.500000 -0.500000   \n",
       "2 1964-03-31    0.166667  0.083333 -0.083333 -0.458333    0.375000 -0.333333   \n",
       "3 1964-04-30   -0.416667 -0.250000 -0.166667  0.125000   -0.083333 -0.125000   \n",
       "4 1964-05-31   -0.250000  0.500000  0.125000  0.000000   -0.083333 -0.041667   \n",
       "\n",
       "    ME2 BM2   ME2 BM3   ME2 BM4  ...   ME4 BM1   ME4 BM2   ME4 BM3   ME4 BM4   \n",
       "0 -0.250000  0.041667  0.000000  ... -0.208333  0.083333  0.208333  0.458333  \\\n",
       "1 -0.458333  0.250000 -0.250000  ... -0.416667 -0.125000 -0.291667  0.208333   \n",
       "2 -0.208333  0.041667 -0.125000  ... -0.041667 -0.291667  0.125000  0.500000   \n",
       "3  0.041667  0.083333  0.375000  ... -0.208333  0.000000  0.291667  0.500000   \n",
       "4 -0.500000  0.291667 -0.291667  ... -0.458333  0.250000  0.416667 -0.416667   \n",
       "\n",
       "    ME4 BM5  BIG LoBM   ME5 BM2   ME5 BM3   ME5 BM4  BIG HiBM  \n",
       "0  0.500000  0.416667  0.333333  0.291667  0.375000  0.250000  \n",
       "1  0.166667  0.000000  0.083333 -0.208333 -0.083333 -0.166667  \n",
       "2  0.416667 -0.166667 -0.416667 -0.375000  0.291667  0.208333  \n",
       "3 -0.375000 -0.291667 -0.333333  0.208333  0.166667 -0.458333  \n",
       "4 -0.375000  0.208333  0.375000  0.333333 -0.125000  0.458333  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_signal_df = rank_and_map(signal_df)\n",
    "normalized_signal_df = normalized_signal_df[(normalized_signal_df['date'].dt.year > starting_year_to_filter) & (normalized_signal_df['date'].dt.year < end_year_to_filter)].reset_index(drop=True)\n",
    "normalized_signal_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix can be denoted as $R_{t-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SMALL LoBM</th>\n",
       "      <th>ME1 BM2</th>\n",
       "      <th>ME1 BM3</th>\n",
       "      <th>ME1 BM4</th>\n",
       "      <th>SMALL HiBM</th>\n",
       "      <th>ME2 BM1</th>\n",
       "      <th>ME2 BM2</th>\n",
       "      <th>ME2 BM3</th>\n",
       "      <th>ME2 BM4</th>\n",
       "      <th>...</th>\n",
       "      <th>ME4 BM1</th>\n",
       "      <th>ME4 BM2</th>\n",
       "      <th>ME4 BM3</th>\n",
       "      <th>ME4 BM4</th>\n",
       "      <th>ME4 BM5</th>\n",
       "      <th>BIG LoBM</th>\n",
       "      <th>ME5 BM2</th>\n",
       "      <th>ME5 BM3</th>\n",
       "      <th>ME5 BM4</th>\n",
       "      <th>BIG HiBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964-01-31</td>\n",
       "      <td>1.613832</td>\n",
       "      <td>0.536932</td>\n",
       "      <td>1.849632</td>\n",
       "      <td>1.777732</td>\n",
       "      <td>2.481732</td>\n",
       "      <td>-4.392368</td>\n",
       "      <td>-2.864868</td>\n",
       "      <td>1.267032</td>\n",
       "      <td>-0.894568</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.688568</td>\n",
       "      <td>-0.540368</td>\n",
       "      <td>-1.285868</td>\n",
       "      <td>1.231832</td>\n",
       "      <td>0.966432</td>\n",
       "      <td>0.730232</td>\n",
       "      <td>0.826532</td>\n",
       "      <td>-0.754868</td>\n",
       "      <td>-0.276068</td>\n",
       "      <td>-0.747368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1964-02-29</td>\n",
       "      <td>0.194676</td>\n",
       "      <td>0.090576</td>\n",
       "      <td>-0.496824</td>\n",
       "      <td>-2.474524</td>\n",
       "      <td>1.690076</td>\n",
       "      <td>-1.146724</td>\n",
       "      <td>-1.036524</td>\n",
       "      <td>-0.103724</td>\n",
       "      <td>-0.641224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345224</td>\n",
       "      <td>-1.112324</td>\n",
       "      <td>0.098976</td>\n",
       "      <td>4.429176</td>\n",
       "      <td>1.845576</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>-2.243324</td>\n",
       "      <td>-1.563724</td>\n",
       "      <td>1.083376</td>\n",
       "      <td>0.986876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1964-03-31</td>\n",
       "      <td>-2.581656</td>\n",
       "      <td>-1.576556</td>\n",
       "      <td>-0.881556</td>\n",
       "      <td>0.463844</td>\n",
       "      <td>-0.262556</td>\n",
       "      <td>-0.741356</td>\n",
       "      <td>0.120944</td>\n",
       "      <td>0.271144</td>\n",
       "      <td>2.594944</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.097756</td>\n",
       "      <td>-0.063256</td>\n",
       "      <td>2.110444</td>\n",
       "      <td>4.037044</td>\n",
       "      <td>-2.362856</td>\n",
       "      <td>-1.927556</td>\n",
       "      <td>-2.320556</td>\n",
       "      <td>0.729344</td>\n",
       "      <td>0.541144</td>\n",
       "      <td>-2.935256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1964-04-30</td>\n",
       "      <td>-1.015160</td>\n",
       "      <td>3.135640</td>\n",
       "      <td>0.094940</td>\n",
       "      <td>-0.361260</td>\n",
       "      <td>-0.374860</td>\n",
       "      <td>-0.361460</td>\n",
       "      <td>-3.334660</td>\n",
       "      <td>1.354440</td>\n",
       "      <td>-1.066060</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.151560</td>\n",
       "      <td>0.884440</td>\n",
       "      <td>2.576040</td>\n",
       "      <td>-2.087360</td>\n",
       "      <td>-1.732360</td>\n",
       "      <td>0.781940</td>\n",
       "      <td>2.022140</td>\n",
       "      <td>1.358440</td>\n",
       "      <td>-0.412560</td>\n",
       "      <td>2.965240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1964-05-31</td>\n",
       "      <td>-2.800664</td>\n",
       "      <td>-2.863364</td>\n",
       "      <td>-1.009764</td>\n",
       "      <td>-1.201064</td>\n",
       "      <td>-0.119164</td>\n",
       "      <td>1.596436</td>\n",
       "      <td>-1.139464</td>\n",
       "      <td>1.466336</td>\n",
       "      <td>0.305336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504664</td>\n",
       "      <td>0.772236</td>\n",
       "      <td>-0.103364</td>\n",
       "      <td>-0.204564</td>\n",
       "      <td>2.552136</td>\n",
       "      <td>0.523836</td>\n",
       "      <td>-1.212564</td>\n",
       "      <td>-0.175564</td>\n",
       "      <td>2.605636</td>\n",
       "      <td>1.837536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  SMALL LoBM   ME1 BM2   ME1 BM3   ME1 BM4  SMALL HiBM   ME2 BM1   \n",
       "0 1964-01-31    1.613832  0.536932  1.849632  1.777732    2.481732 -4.392368  \\\n",
       "1 1964-02-29    0.194676  0.090576 -0.496824 -2.474524    1.690076 -1.146724   \n",
       "2 1964-03-31   -2.581656 -1.576556 -0.881556  0.463844   -0.262556 -0.741356   \n",
       "3 1964-04-30   -1.015160  3.135640  0.094940 -0.361260   -0.374860 -0.361460   \n",
       "4 1964-05-31   -2.800664 -2.863364 -1.009764 -1.201064   -0.119164  1.596436   \n",
       "\n",
       "    ME2 BM2   ME2 BM3   ME2 BM4  ...   ME4 BM1   ME4 BM2   ME4 BM3   ME4 BM4   \n",
       "0 -2.864868  1.267032 -0.894568  ... -2.688568 -0.540368 -1.285868  1.231832  \\\n",
       "1 -1.036524 -0.103724 -0.641224  ... -0.345224 -1.112324  0.098976  4.429176   \n",
       "2  0.120944  0.271144  2.594944  ... -1.097756 -0.063256  2.110444  4.037044   \n",
       "3 -3.334660  1.354440 -1.066060  ... -2.151560  0.884440  2.576040 -2.087360   \n",
       "4 -1.139464  1.466336  0.305336  ... -0.504664  0.772236 -0.103364 -0.204564   \n",
       "\n",
       "    ME4 BM5  BIG LoBM   ME5 BM2   ME5 BM3   ME5 BM4  BIG HiBM  \n",
       "0  0.966432  0.730232  0.826532 -0.754868 -0.276068 -0.747368  \n",
       "1  1.845576 -0.934724 -2.243324 -1.563724  1.083376  0.986876  \n",
       "2 -2.362856 -1.927556 -2.320556  0.729344  0.541144 -2.935256  \n",
       "3 -1.732360  0.781940  2.022140  1.358440 -0.412560  2.965240  \n",
       "4  2.552136  0.523836 -1.212564 -0.175564  2.605636  1.837536  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demeaned_return_df = cross_sectional_demean(df_25_ff_size_value_sorted_monthly)\n",
    "demeaned_return_df = demeaned_return_df[(demeaned_return_df['date'].dt.year > starting_year_to_filter) & (demeaned_return_df['date'].dt.year < end_year_to_filter)].reset_index(drop=True)\n",
    "demeaned_return_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives: $R_{t}S'_{t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_matrix = compute_rs_product(demeaned_return_df, normalized_signal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction matrix for date T+1, used returns data up to month T and signals data up to month T-1. In the function get_prediction_matrix, I start the calculations from the previous month. Note that although the input date is the current data, but the in the function that month is excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in calculating realized returns, I am using the current month(the month of rearlized returns) as index. But remember that the matrix was $S_{t-1}$. So, the index actually retreives the value of the previous month. I formed the matrix this way in order to make the calculations easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pep] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[realized_col_name_pap] = None\n",
      "C:\\Users\\Amin\\AppData\\Local\\Temp\\ipykernel_4020\\1428712266.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  realized_returns_df[expected_col_name_pap] = None\n"
     ]
    }
   ],
   "source": [
    "# I leave out the first 120 observations to compute the prediction matrix.\n",
    "\n",
    "\n",
    "realized_returns_df = pd.DataFrame(columns=[\n",
    "    \"date\",\n",
    "    \"return_of_simple_factor\", \n",
    "    \"realized_return_of_first_three_PP\", \n",
    "    \"expected_return_of_first_three_PP\",\n",
    "    \"realized_return_of_first_three_PEP\",\n",
    "    \"expected_return_of_first_three_PEP\",\n",
    "    \"realized_return_of_first_three_PAP\",\n",
    "    \"expected_return_of_first_three_PAP\"\n",
    "])\n",
    "\n",
    "for date_index in demeaned_return_df.iloc[number_of_lookback_periods:]['date']:\n",
    "    date_to_consider = pd.Timestamp(date_index)\n",
    "    \n",
    "    #for PP's\n",
    "    prediction_matrix = get_prediction_matrix(date_to_consider, rs_matrix, number_of_lookback_periods)\n",
    "    U, S, VT = np.linalg.svd(prediction_matrix)\n",
    "\n",
    "    #for PEP's\n",
    "    Symmetric_prediction_matrix = (prediction_matrix + prediction_matrix.T)/2\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(Symmetric_prediction_matrix)\n",
    "    idx = eigenvalues.argsort()[::-1]  # Sort in descending order\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "    # for PAP'S\n",
    "    assymetric_prediction_matrix = 0.5 * (prediction_matrix - prediction_matrix.T)\n",
    "    transposed_assymetric_prediction_matrix = assymetric_prediction_matrix.T\n",
    "    eigenvalues_ta, eigenvectors_ta = np.linalg.eig(transposed_assymetric_prediction_matrix)\n",
    "    sorted_indices_ta = np.argsort(-eigenvalues_ta.imag)\n",
    "    sorted_eigenvalues_ta = eigenvalues_ta[sorted_indices_ta].imag\n",
    "    sorted_eigenvectors_ta = eigenvectors_ta[:, sorted_indices_ta] * math.sqrt(2)  #sqrt(2) is to make the size of the vectors equal to 1.\n",
    "    positive_indices = np.where(sorted_eigenvalues_ta > 0)\n",
    "    filtered_eigenvalues_ta = sorted_eigenvalues_ta[positive_indices]\n",
    "    filtered_eigenvectors_ta = sorted_eigenvectors_ta[:, positive_indices].squeeze()\n",
    "    sorted_eigenvectors_ta_imaginary_part = filtered_eigenvectors_ta.imag\n",
    "    sorted_eigenvectors_ta_real_part = filtered_eigenvectors_ta.real\n",
    "\n",
    "    #to calculate realized returns\n",
    "    signal_vector = normalized_signal_df[normalized_signal_df.date == date_to_consider].values[0, 1:].reshape(1, -1)  # 1*n matrix\n",
    "    return_vector = df_25_ff_size_value_sorted_monthly[df_25_ff_size_value_sorted_monthly.date == date_to_consider].values[0, 1:].reshape(-1, 1)  # n*1  # there is not much difference between using demeaned returns or not_demeaned ones. I can replace df_25_ff_size_value_sorted_monthly with demeaned_return_df.\n",
    "    \n",
    "\n",
    "    # Compute realized returns\n",
    "    return_of_simple_factor = (signal_vector @ return_vector)[0][0]\n",
    "    realized_return_of_first_three_PP = (signal_vector @ first_n_PPs_position_matrix(U, VT, number_of_PPs_to_consider) @ return_vector)[0][0]\n",
    "    expected_return_of_first_three_PP = first_n_PPs_expected_return(S, number_of_PPs_to_consider)\n",
    "    realized_return_of_first_three_PEP = (signal_vector @ first_n_PEPs_position_matrix(eigenvectors,number_of_PEPs_to_consider) @ return_vector)[0][0]\n",
    "    expected_return_of_first_three_PEP = first_n_PEPs_expected_return(eigenvalues, number_of_PEPs_to_consider)\n",
    "    realized_return_of_first_three_PAP = (signal_vector @ first_n_PAPs_position_matrix(sorted_eigenvectors_ta_real_part,sorted_eigenvectors_ta_imaginary_part,number_of_PAPs_to_consider) @ return_vector)[0][0]\n",
    "    expected_return_of_first_three_PAP = first_n_PAPs_expected_return(filtered_eigenvalues_ta, number_of_PAPs_to_consider)\n",
    "    \n",
    "\n",
    "    # Prepare a list for the current row values\n",
    "    row_values = [\n",
    "        date_index,\n",
    "        return_of_simple_factor,  \n",
    "        realized_return_of_first_three_PP, \n",
    "        expected_return_of_first_three_PP,\n",
    "        realized_return_of_first_three_PEP,\n",
    "        expected_return_of_first_three_PEP,\n",
    "        realized_return_of_first_three_PAP,\n",
    "        expected_return_of_first_three_PAP\n",
    "    ]\n",
    "\n",
    "    # Iterate over all Principal Portfolios (up to len(S)) and calculate realized/expected returns for each\n",
    "    for i in range(len(S)):\n",
    "\n",
    "        # for PP's\n",
    "        realized_return_ith_PP = (signal_vector @ get_ith_position_matrix(U, VT, i) @ return_vector)[0][0]\n",
    "        expected_return_ith_PP = get_ith_PPs_expected_return(S, i)\n",
    "        # Add the values for realized and expected returns of the ith PP to the row\n",
    "        row_values.append(realized_return_ith_PP)\n",
    "        row_values.append(expected_return_ith_PP)\n",
    "\n",
    "        # for PEP's\n",
    "        realized_return_ith_PEP = (signal_vector @ get_ith_symmetric_position_matrix(eigenvectors, i) @ return_vector)[0][0]\n",
    "        expected_return_ith_PEP = get_ith_PEPs_expected_return(eigenvalues, i)\n",
    "        # Add the values for realized and expected returns of the ith PEP to the row\n",
    "        row_values.append(realized_return_ith_PEP)\n",
    "        row_values.append(expected_return_ith_PEP)\n",
    "\n",
    "\n",
    "        # Dynamically add columns if they don't exist. for PP's.\n",
    "        realized_col_name_pp = f\"realized_return_of_{i+1}_PP\"\n",
    "        expected_col_name_pp = f\"expected_return_of_{i+1}_PP\"\n",
    "\n",
    "        # Dynamically add columns if they don't exist. for PEP's.\n",
    "        realized_col_name_pep = f\"realized_return_of_{i+1}_PEP\"\n",
    "        expected_col_name_pep = f\"expected_return_of_{i+1}_PEP\"\n",
    "        \n",
    "        # for PP's\n",
    "        if realized_col_name_pp not in realized_returns_df.columns:\n",
    "            realized_returns_df[realized_col_name_pp] = None\n",
    "        if expected_col_name_pp not in realized_returns_df.columns:\n",
    "            realized_returns_df[expected_col_name_pp] = None\n",
    "\n",
    "        #for PEP'S\n",
    "        if realized_col_name_pep not in realized_returns_df.columns:\n",
    "            realized_returns_df[realized_col_name_pep] = None\n",
    "        if expected_col_name_pep not in realized_returns_df.columns:\n",
    "            realized_returns_df[expected_col_name_pep] = None\n",
    "\n",
    "    for i in range(sorted_eigenvectors_ta_imaginary_part.shape[1]):\n",
    "        # for PAP's\n",
    "        realized_return_ith_PAP = (signal_vector @ get_ith_asymmetric_position_matrix(sorted_eigenvectors_ta_real_part,sorted_eigenvectors_ta_imaginary_part,i) @ return_vector)[0][0]\n",
    "        expected_return_ith_PAP = get_ith_PAPs_expected_return(filtered_eigenvalues_ta,i)\n",
    "        # Add the values for realized and expected returns of the ith PEP to the row\n",
    "        row_values.append(realized_return_ith_PAP)\n",
    "        row_values.append(expected_return_ith_PAP)\n",
    "\n",
    "        # Dynamically add columns if they don't exist. for PEP's.\n",
    "        realized_col_name_pap = f\"realized_return_of_{i+1}_PAP\"\n",
    "        expected_col_name_pap = f\"expected_return_of_{i+1}_PAP\"\n",
    "\n",
    "        #for PAP'S\n",
    "        if realized_col_name_pap not in realized_returns_df.columns:\n",
    "            realized_returns_df[realized_col_name_pap] = None\n",
    "        if expected_col_name_pap not in realized_returns_df.columns:\n",
    "            realized_returns_df[expected_col_name_pap] = None\n",
    "\n",
    "    # Append the row to the dataframe\n",
    "    realized_returns_df.loc[len(realized_returns_df)] = row_values\n",
    "\n",
    "realized_returns_df = realized_returns_df.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pap_std = realized_returns_df['realized_return_of_first_three_PAP'].std()\n",
    "pep_std = realized_returns_df['realized_return_of_first_three_PEP'].std()\n",
    "\n",
    "realized_returns_df['adjusted_PAP'] = realized_returns_df['realized_return_of_first_three_PAP'] * (pep_std / pap_std)\n",
    "\n",
    "# Step 2: Take the average of the adjusted \"PAP\" and \"PEP\"\n",
    "realized_returns_df['PEP and PAP 1-3'] = (realized_returns_df['adjusted_PAP'] + realized_returns_df['realized_return_of_first_three_PEP']) / 2\n",
    "\n",
    "# Optional: drop the adjusted column if you don't need it anymore\n",
    "realized_returns_df.drop(columns='adjusted_PAP', inplace=True)\n",
    "\n",
    "\n",
    "sharpe_df = realized_returns_df.drop(realized_returns_df.filter(like=\"expected\").columns, axis=1).apply(lambda col: calculate_sharpe_ratio(col)) * math.sqrt(12)\n",
    "\n",
    "pp_columns = realized_returns_df.filter(like=\"PP\")\n",
    "pp_realized_mean_df = pp_columns.filter(like=\"realized\").mean(axis=0)\n",
    "pp_expected_mean_df = pp_columns.filter(like=\"expected\").mean(axis=0)\n",
    "\n",
    "pep_columns = realized_returns_df.filter(like=\"PEP\")\n",
    "pep_realized_mean_df = pep_columns.filter(like=\"realized\").mean(axis=0)\n",
    "pep_expected_mean_df = pep_columns.filter(like=\"expected\").mean(axis=0)\n",
    "\n",
    "pap_columns = realized_returns_df.filter(like=\"PAP\")\n",
    "pap_realized_mean_df = pap_columns.filter(like=\"realized\").mean(axis=0)\n",
    "pap_expected_mean_df = pap_columns.filter(like=\"expected\").mean(axis=0)\n",
    "\n",
    "realized_returns_df.to_csv(\"temp/realized_returns.csv\")\n",
    "sharpe_df.to_csv(\"temp/sharpe.csv\")\n",
    "\n",
    "pp_columns.to_csv(\"temp/pp_columns.csv\")\n",
    "pp_realized_mean_df.to_csv(\"temp/pp_realized_mean_df.csv\")\n",
    "pp_expected_mean_df.to_csv(\"temp/pp_expected_mean_df.csv\")\n",
    "\n",
    "pep_columns.to_csv(\"temp/pep_columns.csv\")\n",
    "pep_realized_mean_df.to_csv(\"temp/pep_realized_mean_df.csv\")\n",
    "pep_expected_mean_df.to_csv(\"temp/pep_expected_mean_df.csv\")\n",
    "\n",
    "pap_columns.to_csv(\"temp/pap_columns.csv\")\n",
    "pap_realized_mean_df.to_csv(\"temp/pap_realized_mean_df.csv\")\n",
    "pap_expected_mean_df.to_csv(\"temp/pap_expected_mean_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "return_of_simple_factor               0.415765\n",
       "realized_return_of_first_three_PP     0.774135\n",
       "realized_return_of_first_three_PEP    0.487988\n",
       "realized_return_of_first_three_PAP    0.552814\n",
       "realized_return_of_1_PP               0.481485\n",
       "                                        ...   \n",
       "realized_return_of_9_PAP             -0.056908\n",
       "realized_return_of_10_PAP             0.015806\n",
       "realized_return_of_11_PAP            -0.040131\n",
       "realized_return_of_12_PAP             0.069891\n",
       "PEP and PAP 1-3                       0.776921\n",
       "Length: 67, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharpe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "realized_returns_df, factor_data_monthly = filter_dataframes_by_common_dates(realized_returns_df,factor_data_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 6.75901528,  0.02612368, -0.08107415,  0.19936143, -0.01035099,\n",
       "        -0.10072436,  0.35732928]),\n",
       " array([ 4.34344091,  0.83669919, -1.78015137,  3.3844652 , -0.17170449,\n",
       "        -1.07708357, 27.5893206 ]),\n",
       " 0.6866793588839745,\n",
       " 0.6008633838736177]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = factor_data_monthly[['Mkt-RF', 'SMB','HML','RMW','CMA']]\n",
    "X = pd.concat([X, realized_returns_df['return_of_simple_factor']], axis=1)\n",
    "# Dependent variable (Y)\n",
    "Y = realized_returns_df['realized_return_of_first_three_PP']\n",
    "\n",
    "#Y = realized_returns_df['PEP and PAP 1-3']\n",
    "#Y = realized_returns_df['return_of_simple_factor']\n",
    "# Create and fit the model\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "regression_results(X,Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for regression_result_realized_return_of_first_three_PP:\n",
      "0.6008633838736177\n",
      "Results for regression_result_realized_return_of_first_three_PEP:\n",
      "0.8921470173273893\n",
      "Results for regression_result_realized_return_of_first_three_PAP:\n",
      "0.050819266744861036\n",
      "Results for regression_result_PEP and PAP 1-3:\n",
      "0.4223392326177122\n"
     ]
    }
   ],
   "source": [
    "# List of column names in realized_returns_df for which I want to perform the regression\n",
    "columns_to_iterate = ['realized_return_of_first_three_PP',\n",
    "                      'realized_return_of_first_three_PEP',\n",
    "                      'realized_return_of_first_three_PAP',\n",
    "                       'PEP and PAP 1-3'] \n",
    "\n",
    "# Create a list to store the results\n",
    "regression_results_list = []\n",
    "\n",
    "# Iterate over each column\n",
    "for col in columns_to_iterate:\n",
    "    # Set Y to the column from realized_returns_df\n",
    "    Y = realized_returns_df[col]\n",
    "    \n",
    "    # Store the results with a variable name based on the column name\n",
    "    result_name = f'regression_result_{col}'\n",
    "    regression_results_list.append((result_name, regression_results(X,Y)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
